## dl

dl is a small library that I made to understand how neural networks work. It uses [momentum](https://distill.pub/2017/momentum/). I wanted to implement backpropagation from scratch (reference - [this](http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf) paper, page 9) - I also proved the update rules on my own. It wasn't too hard. We just use the chain rule in a fancy way.  

## gates.ipynb

Using a neural network to simulate AND, OR, XOR and NOT logic gates.

## mnist.ipynb

Playing around with parameters and testing it on the MNIST dataset. 97% acc on MNIST using sigmoid after 3 hours of training. 96% acc on MNIST using ReLU after 10 minutes of training. 98% accuracy after using He initialization.   

## real.ipynb

Using images I took on my phone.

## proof.pdf

My solutions to exercises [here](neuralnetworksanddeeplearning.com) + some more. 
